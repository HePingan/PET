{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查询pip下载当前所使用的源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global.index-url='https://mirror.sjtu.edu.cn/pypi/web/simple/'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip config list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 换源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常使用的源：<br />\n",
    "清华：https://pypi.tuna.tsinghua.edu.cn/simple/ <br />\n",
    "阿里云：http://mirrors.aliyun.com/pypi/simple/ <br />\n",
    "中国科技大学：https://pypi.mirrors.ustc.edu.cn/simple/ <br />\n",
    "华中科技大学：http://pypi.hustunique.com/simple/ <br />\n",
    "上海交通大学：https://mirror.sjtu.edu.cn/pypi/web/simple/ <br />\n",
    "豆瓣：http://pypi.douban.com/simple/ <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip config set global.index-url 源地址"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 导入包的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os: 用于与操作系统进行交互，例如文件和文件夹的操作。\n",
    "# sys: 提供了访问Python解释器的变量和函数的功能。\n",
    "# sys: 提供了访问Python解释器的变量和函数的功能。\n",
    "# argparse: 用于解析命令行参数和选项。\n",
    "import os, sys, glob, argparse\n",
    "import pandas as pd #提供数据分析工具，主要用于处理和分析数据表格。\n",
    "import numpy as np #提供多维数组对象和用于处理数组的函数。\n",
    "from tqdm import tqdm #提供多维数组对象和用于处理数组的函数。\n",
    "\n",
    "import cv2 #用于图像处理和计算机视觉任务。\n",
    "from PIL import Image #用于图像处理，类似于OpenCV，但主要用于处理图像。\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "# train_test_split:数据集划分 StratifiedKFold:分层交叉验证 KFold:普通的K折交叉验证\n",
    "import torch\n",
    "# 初始化随机数生成器的种子\n",
    "torch.manual_seed(0)\n",
    "# 这行代码设置PyTorch的CuDNN后端不使用确定性算法。CuDNN是用于GPU加速的深度学习库，通过设置为False，可以在一定程度上提高性能。\n",
    "torch.backends.cudnn.deterministic = False\n",
    "# 这行代码启用CuDNN的自动优化机制，以加速深度卷积神经网络的训练。\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models #提供了许多预训练的深度学习模型，例如VGG等\n",
    "import torchvision.transforms as transforms #该模块提供了各种用于图像数据预处理和增强的转换函数\n",
    "import torchvision.datasets as datasets #该模块提供了多个流行的计算机视觉数据集\n",
    "import torch.nn as nn #构建和操作神经网络的核心模块之一\n",
    "import torch.nn.functional as F #用于在网络的前向传播过程中执行一些非参数化的操作，激活函数、池化、归一化等\n",
    "import torch.optim as optim #定义和实现各种优化算法的模块\n",
    "from torch.autograd import Variable #实现自动微分\n",
    "from torch.utils.data.dataset import Dataset #数据加载和预处理提供一个统一的接口\n",
    "\n",
    "import albumentations as A # 用于图像数据增强的强大库\n",
    "import nibabel as nib #NIFTI 数据格式处理库\n",
    "import matplotlib.pyplot as plt\n",
    "from nibabel.viewers import OrthoSlicer3D #用于创建交互式的三维正交切片可视化，用于显示 NIFTI 格式的神经影像数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 查看nii文件的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取.nii文件\n",
    "nii_path = r'/home/aistudio/─╘PET═╝╧ё╖╓╬Ў║═╝▓▓б╘д▓т╠Ї╒╜╚№╣л┐к╩¤╛▌/Test/1.nii'\n",
    "nii_img = nib.load(nii_path)\n",
    "\n",
    "# 获取图像数据\n",
    "nii_data = nii_img.get_fdata()\n",
    "\n",
    "# 可选：查看图像属性\n",
    "print(\"图像形状:\", nii_data.shape)\n",
    "print(\"像素尺寸:\", nii_img.header.get_zooms())\n",
    "\n",
    "# 可根据需要更改切片索引\n",
    "slice_index = nii_data.shape[2]  // 2\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(nii_data[:, :, slice_index, 0], cmap='gray') \n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(nii_data[:, slice_index,:, 0], cmap='gray') \n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(nii_data[slice_index ,: , : , 0], cmap='gray') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 查看每张nii图片的形状及深度，发现有几种不同的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "print('图片形状：',nib.load(train_path[0]).shape) # 查看一张nii图片，包含高度，宽度，深度和通道数\n",
    "dict1 = defaultdict(int)  # 创建一个默认值为0的字典，深度\n",
    "dict2 = defaultdict(int)  # 创建一个默认值为0的字典，宽度和高度\n",
    "for t in train_path:\n",
    "  nii_img = nib.load(t)\n",
    "  dict1[nii_img.shape[-2]] += 1\n",
    "  dict2[nii_img.shape[1]] += 1\n",
    "print(dict1)# 每张图片的深度不同，出现频率最高的是深度63，出现了24次\n",
    "print(dict2) # 每张图片的高度和宽度不同，出现频率最高的是高和宽为128，出现了42次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet18的主要结构和一些特点："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输入层：ResNet-18接受大小为224x224的彩色图像作为输入。\n",
    "\n",
    "- 卷积层和池化层：ResNet-18开始以一个7x7的卷积核进行卷积操作，然后经过最大池化层，步长为2。之后，通过四个阶段，每个阶段有不同数量的残差块。每个阶段的特征图尺寸逐渐减小，但特征图的数量逐渐增加。\n",
    "\n",
    "- 残差块：每个残差块由两个3x3的卷积层组成，卷积层之间有一个跳跃连接，绕过了一个Batch Normalization 层和一个ReLU激活函数。这个跳跃连接可以用一个1x1的卷积层来匹配维度。这种结构允许模型可以学习到残差，避免了训练深度网络时的梯度消失问题。\n",
    "\n",
    "- 全局平均池化：ResNet-18的最后一层是一个全局平均池化层，将特征图的高和宽维度缩减为1，最终得到每个通道的特征图。\n",
    "\n",
    "- 全连接层：最后通过一个全连接层将最终的特征映射到类别数。\n",
    "\n",
    "ResNet-18在许多计算机视觉任务中都表现出色，尤其在图像分类、目标检测和语义分割等领域。它的深度相对较浅，仍然具有强大的表达能力。如果任务需要更深的网络，可以考虑使用更深层次的ResNet变种，如ResNet-34、ResNet-50、ResNet-101和ResNet-152等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 自定义数据集（Dataset）的用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义数据集类需要继承自 torch.utils.data.Dataset 类，并实现以下三个方法：__init__、__len__ 和 __getitem__。这样可以方便地在训练时加载、处理和传递数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        \"\"\"\n",
    "        初始化方法，接收数据和标签，以及可选的数据变换方法。\n",
    "        Args:\n",
    "            data (list or ndarray): 数据列表或数组。\n",
    "            labels (list or ndarray): 标签列表或数组。\n",
    "            transform (callable, optional): 数据变换方法。默认为 None。\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集的大小（样本数量）。\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取数据集中的一个样本数据和其对应的标签。\n",
    "        Args:\n",
    "            index (int): 样本索引。\n",
    "        Returns:\n",
    "            sample (Tensor or ndarray): 样本数据。\n",
    "            label (Tensor or int): 样本标签。\n",
    "        \"\"\"\n",
    "        sample = self.data[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)  # 对数据应用变换方法\n",
    "\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一般步骤**\n",
    "1. 准备数据和标签，可以是列表、数组等形式。\n",
    "2. 定义数据变换方法（可选），如图像的预处理操作。\n",
    "3. 创建自定义数据集的实例，并传入数据、标签和变换方法（如果有的话）。\n",
    "4. 使用数据加载器（torch.utils.data.DataLoader）加载自定义数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
